{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1799 datapoints in the dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>url</th>\n",
       "      <th>industry</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Series D</td>\n",
       "      <td>./BestPitchPDFs/bolt.pdf</td>\n",
       "      <td>Tech</td>\n",
       "      <td>bolt bolt growing scaled global network around...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Late Stage</td>\n",
       "      <td>./BestPitchPDFs/spotify.pdf</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>distributed computer science aes cry language ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Late Stage</td>\n",
       "      <td>./BestPitchPDFs/wework.pdf</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>space service whore fundamental community cyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pre-Seed</td>\n",
       "      <td>./BestPitchPDFs/airbnb.pdf</td>\n",
       "      <td>Travel and Hospitality</td>\n",
       "      <td>welcome breakfast book rather problem price im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Early Stage</td>\n",
       "      <td>./BestPitchPDFs/facebook.pdf</td>\n",
       "      <td>Media and Advertising</td>\n",
       "      <td>ers sie aes oes see classes bee directory user...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         stage                           url                industry  \\\n",
       "0     Series D      ./BestPitchPDFs/bolt.pdf                    Tech   \n",
       "1   Late Stage   ./BestPitchPDFs/spotify.pdf           Entertainment   \n",
       "2   Late Stage    ./BestPitchPDFs/wework.pdf             Real Estate   \n",
       "3     Pre-Seed    ./BestPitchPDFs/airbnb.pdf  Travel and Hospitality   \n",
       "4  Early Stage  ./BestPitchPDFs/facebook.pdf   Media and Advertising   \n",
       "\n",
       "                                                text  \n",
       "0  bolt bolt growing scaled global network around...  \n",
       "1  distributed computer science aes cry language ...  \n",
       "2  space service whore fundamental community cyst...  \n",
       "3  welcome breakfast book rather problem price im...  \n",
       "4  ers sie aes oes see classes bee directory user...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/aya/Dextract_DL/data/processed_pitch_data.csv'\n",
    "data = pd.read_csv(path).drop('Unnamed: 0', axis=1)\n",
    "data.columns = ['stage', 'url', 'industry', 'text']\n",
    "print(f'There are {data.shape[0]} datapoints in the dataset.')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices of rows with NaN values in the 'text' column: [376, 436, 869, 871, 873, 877, 929, 935, 963, 976, 977, 1075, 1081, 1098, 1099, 1118, 1158, 1208, 1223, 1269, 1278, 1284, 1295, 1320, 1328, 1338, 1575, 1619, 1723]\n"
     ]
    }
   ],
   "source": [
    "nan_indices = data[data['text'].isna()].index\n",
    "print(f\"indices of rows with NaN values in the 'text' column: {list(nan_indices)}\")\n",
    "#drop these rows\n",
    "data = data.drop(nan_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finance and Banking              237\n",
      "Health Care                      211\n",
      "Enterprise                       201\n",
      "Consumer                         193\n",
      "Data Analytics and Management    166\n",
      "Tech                             165\n",
      "Media and Advertising            108\n",
      "Entertainment                     82\n",
      "Other                             70\n",
      "Education                         67\n",
      "Cybersecurity                     62\n",
      "Real Estate                       51\n",
      "Name: industry, dtype: int64\n",
      "Index(['Finance and Banking', 'Health Care', 'Enterprise', 'Consumer',\n",
      "       'Data Analytics and Management', 'Tech', 'Media and Advertising',\n",
      "       'Entertainment', 'Other', 'Education', 'Cybersecurity', 'Real Estate'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "pitch_count = data.industry.value_counts()\n",
    "pitch_count\n",
    "low_count_industries = pitch_count[pitch_count < 50].index\n",
    "# Remove industries with less than 50 pitches\n",
    "data = data[~data.industry.isin(low_count_industries)]\n",
    "print(data.industry.value_counts())\n",
    "print(data.industry.value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "x_data = data.text.tolist()\n",
    "y_data = data.industry.tolist()\n",
    "train, test, y_train_raw, y_test_raw = train_test_split(x_data, y_data, \n",
    "                                                test_size=0.2, \n",
    "                                                #random_state=42, \n",
    "                                                stratify=data.industry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id = {\n",
    "    'Finance and Banking': 0,\n",
    "    'Health Care': 1,\n",
    "    'Enterprise': 2,\n",
    "    'Consumer': 3,\n",
    "    'Data Analytics and Management': 4,\n",
    "    'Tech': 5,\n",
    "    'Media and Advertising': 6,\n",
    "    'Entertainment': 7,\n",
    "    'Other': 8,\n",
    "    'Education': 9,\n",
    "    'Cybersecurity': 10,\n",
    "    'Real Estate': 11\n",
    "}\n",
    "\n",
    "y_train = [label_to_id[label] for label in y_train_raw]\n",
    "y_test = [label_to_id[label] for label in y_test_raw]\n",
    "num_labels = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PitchDeckDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"label\": torch.tensor(label, dtype=torch.long),\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PitchDeckDataset(train, y_train, tokenizer, max_length=256)\n",
    "test_dataset = PitchDeckDataset(test, y_test, tokenizer, max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    return {\"accuracy\": (preds == labels).mean()}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aya/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='486' max='486' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [486/486 2:07:13, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.345300</td>\n",
       "      <td>1.561682</td>\n",
       "      <td>0.541796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.058200</td>\n",
       "      <td>1.333440</td>\n",
       "      <td>0.585139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.903200</td>\n",
       "      <td>1.284782</td>\n",
       "      <td>0.619195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 1.2847822904586792, 'eval_accuracy': 0.6191950464396285, 'eval_runtime': 183.2949, 'eval_samples_per_second': 1.762, 'eval_steps_per_second': 0.224, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "# Evaluate model\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Evaluation results:\", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)\n",
    "predicted_labels = np.argmax(predictions.predictions, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.77      0.73        48\n",
      "           1       0.84      0.86      0.85        42\n",
      "           2       0.56      0.62      0.59        40\n",
      "           3       0.85      0.74      0.79        39\n",
      "           4       0.59      0.48      0.53        33\n",
      "           5       0.25      0.27      0.26        33\n",
      "           6       0.50      0.55      0.52        22\n",
      "           7       0.35      0.41      0.38        17\n",
      "           8       0.73      0.57      0.64        14\n",
      "           9       0.50      0.46      0.48        13\n",
      "          10       0.90      0.75      0.82        12\n",
      "          11       0.86      0.60      0.71        10\n",
      "\n",
      "    accuracy                           0.62       323\n",
      "   macro avg       0.63      0.59      0.61       323\n",
      "weighted avg       0.63      0.62      0.62       323\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
